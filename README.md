# ğŸ‡¹ğŸ‡· Python TÃ¼rk Siyasi Lider Analiz Sistemi

Bu sistem, sosyal medya iÃ§eriklerini analiz ederek TÃ¼rk siyasi liderlerine gÃ¶re kategorize eden ve sentiment analizi yapan Python tabanlÄ± bir AI sistemidir.

## ğŸ“¦ HÄ±zlÄ± Kurulum

### 1. Python ve pip kurulumu
```bash
# Python 3.8+ gerekli
python --version  # 3.8+ olmalÄ±
pip --version
```

### 2. Proje dosyalarÄ±nÄ± indirin
```bash
# Proje klasÃ¶rÃ¼ oluÅŸturun
mkdir turkish-political-analyzer
cd turkish-political-analyzer

# DosyalarÄ± kopyalayÄ±n (yukarÄ±daki kodlarÄ±)
# political_analyzer.py
# web_interface.py
# requirements.txt
```

### 3. Gerekli paketleri yÃ¼kleyin
```bash
pip install -r requirements.txt
```

## ğŸ“‹ requirements.txt

```txt
# Temel baÄŸÄ±mlÄ±lÄ±klar
requests>=2.28.0
pandas>=1.5.0
tqdm>=4.64.0
colorama>=0.4.5

# Web arayÃ¼zÃ¼ iÃ§in (opsiyonel)
streamlit>=1.25.0
plotly>=5.15.0

# GeliÅŸtirme iÃ§in (opsiyonel)
pytest>=7.0.0
black>=22.0.0
flake8>=5.0.0
```

## ğŸš€ KullanÄ±m SeÃ§enekleri

### SeÃ§enek 1: Komut SatÄ±rÄ± (Ã–nerilen - BÃ¼yÃ¼k veri setleri)

```bash
# Temel kullanÄ±m
python political_analyzer.py input.csv output.csv YOUR_API_KEY

# Ã–rnek
python political_analyzer.py sample.csv results.csv AIzaSyCklJ6T0IDgjuH7N8fbWl6AQtJuCEGbRA8

# Ã–zelleÅŸtirilmiÅŸ parametreler
python political_analyzer.py data.csv results.csv YOUR_API_KEY \
  --batch-size 10 \
  --workers 3 \
  --rate-limit 2.0 \
  --max-retries 5

# YardÄ±m
python political_analyzer.py --help
```

### SeÃ§enek 2: Web ArayÃ¼zÃ¼ (Test ve kÃ¼Ã§Ã¼k dosyalar)

```bash
# Web arayÃ¼zÃ¼nÃ¼ baÅŸlat
streamlit run web_interface.py

# TarayÄ±cÄ±da aÃ§Ä±lacak: http://localhost:8501
```

### SeÃ§enek 3: Python Kodunda KullanÄ±m

```python
from political_analyzer import PoliticalAnalysisSystem
import pandas as pd

# Sistem oluÅŸtur
analyzer = PoliticalAnalysisSystem(
    api_key="YOUR_API_KEY",
    batch_size=5,
    max_workers=3,
    rate_limit_sec=1.5
)

# Tek iÃ§erik analizi
result = analyzer.process_single_content(
    "@test_account", 
    "Mansur YavaÅŸ ile harika bir proje yaptÄ±k!"
)
print(result)

# Dosya analizi
analyzer.process_file("input.csv", "output.csv")
```

## ğŸ“Š Ã–rnek CSV FormatÄ±

### Girdi (input.csv):
```csv
ACCOUNT_NAME,TEXT
@burcukoksal03,"Ata tohumlarÄ±mÄ±zÄ± hasat ettik! Mansur YavaÅŸ'la birlikte..."
@user123,"Ekrem Ä°mamoÄŸlu iÃ§in oy vereceÄŸim"
@siyasi_takip,"ErdoÄŸan'Ä±n son aÃ§Ä±klamasÄ± Ã§ok Ã¶nemliydi"
@chp_destekci,"Ã–zgÃ¼r Ã–zel partiye yeni bir soluk getirdi"
```

### Ã‡Ä±ktÄ± (output.csv):
```csv
ACCOUNT_NAME,TEXT,IS_RTE,IS_Ã–Ã–,IS_MY,IS_EI,RTE_SENTIMENT,Ã–Ã–_SENTÄ°MENT,MY_SENTIMENT,EI_SENTIMENT
@burcukoksal03,"Ata tohumlarÄ±mÄ±zÄ± hasat ettik! Mansur YavaÅŸ'la birlikte...",-1,-1,1,-1,,,,1
@user123,"Ekrem Ä°mamoÄŸlu iÃ§in oy vereceÄŸim",-1,-1,-1,1,,,,1
@siyasi_takip,"ErdoÄŸan'Ä±n son aÃ§Ä±klamasÄ± Ã§ok Ã¶nemliydi",1,-1,-1,-1,0,,,
@chp_destekci,"Ã–zgÃ¼r Ã–zel partiye yeni bir soluk getirdi",-1,1,-1,-1,,1,,
```

## ğŸ¯ Sistem Ã–zellikleri

### Agent 1: Lider SÄ±nÄ±flandÄ±rma
Her iÃ§erik iÃ§in hangi liderin ilgili olduÄŸunu belirler:
- **+1**: Ä°lgili lider
- **-1**: Ä°lgisiz liderler

### Agent 2: Sentiment Analizi  
Ä°lgili liderler iÃ§in duygusal ton analizi:
- **+1**: Pozitif (Ã¶vgÃ¼, destek)
- **0**: NÃ¶tr (tarafsÄ±z)
- **-1**: Negatif (eleÅŸtiri)

### Liderler:
- **RTE**: Recep Tayyip ErdoÄŸan
- **Ã–Ã–**: Ã–zgÃ¼r Ã–zel
- **MY**: Mansur YavaÅŸ
- **EI**: Ekrem Ä°mamoÄŸlu

## âš™ï¸ KonfigÃ¼rasyon SeÃ§enekleri

| Parametre | AÃ§Ä±klama | VarsayÄ±lan | AralÄ±k |
|-----------|----------|------------|--------|
| `--batch-size` | AynÄ± anda iÅŸlenecek kayÄ±t sayÄ±sÄ± | 5 | 1-20 |
| `--workers` | Paralel iÅŸlem sayÄ±sÄ± | 3 | 1-10 |
| `--rate-limit` | API Ã§aÄŸrÄ±larÄ± arasÄ± bekleme (saniye) | 1.5 | 0.5-10 |
| `--max-retries` | Maksimum tekrar deneme | 3 | 1-10 |
| `--no-progress` | Progress kaydetmeyi devre dÄ±ÅŸÄ± bÄ±rak | False | - |

## ğŸ“ˆ Performans Optimizasyonu

### HÄ±z vs Maliyet Dengesi

```bash
# HÄ±zlÄ± iÅŸlem (daha maliyetli)
python political_analyzer.py data.csv results.csv API_KEY \
  --batch-size 10 --workers 5 --rate-limit 0.8

# Ekonomik iÅŸlem (daha yavaÅŸ)  
python political_analyzer.py data.csv results.csv API_KEY \
  --batch-size 3 --workers 2 --rate-limit 3.0

# Dengeli iÅŸlem (Ã¶nerilen)
python political_analyzer.py data.csv results.csv API_KEY \
  --batch-size 5 --workers 3 --rate-limit 1.5
```

### Performans Tahminleri

| KayÄ±t SayÄ±sÄ± | Tahmini SÃ¼re | API Ã‡aÄŸrÄ±sÄ± | Tahmini Maliyet |
|-------------|-------------|-------------|----------------|
| 100         | 3-5 dakika  | ~150        | $0.15         |
| 1,000       | 25-35 dakika| ~1,500      | $1.50         |
| 10,000      | 4-6 saat    | ~15,000     | $15.00        |
| 100,000     | 2-3 gÃ¼n     | ~150,000    | $150.00       |

## ğŸ› ï¸ GeliÅŸmiÅŸ KullanÄ±m

### 1. Environment Variables ile KonfigÃ¼rasyon

```bash
# .env dosyasÄ± oluÅŸturun
echo "GOOGLE_API_KEY=your_api_key_here" > .env
echo "BATCH_SIZE=5" >> .env
echo "MAX_WORKERS=3" >> .env
echo "RATE_LIMIT=1.5" >> .env

# Python'da kullanÄ±m
pip install python-dotenv

# Kod iÃ§inde:
from dotenv import load_dotenv
load_dotenv()

api_key = os.getenv('GOOGLE_API_KEY')
```

### 2. BÃ¼yÃ¼k Dosyalar iÃ§in Optimizasyon

```python
# big_file_processor.py
import pandas as pd
from political_analyzer import PoliticalAnalysisSystem

def process_large_file(input_file, output_file, api_key, chunk_size=1000):
    """BÃ¼yÃ¼k CSV dosyalarÄ±nÄ± parÃ§a parÃ§a iÅŸle"""
    
    analyzer = PoliticalAnalysisSystem(api_key, batch_size=3, max_workers=2)
    
    # DosyayÄ± chunk'lar halinde oku
    chunk_iter = pd.read_csv(input_file, chunksize=chunk_size)
    
    all_results = []
    
    for i, chunk in enumerate(chunk_iter):
        print(f"Chunk {i+1} iÅŸleniyor: {len(chunk)} kayÄ±t")
        
        # Chunk'Ä± iÅŸle
        chunk_data = chunk.to_dict('records')
        chunk_results = []
        
        for record in chunk_data:
            result = analyzer.process_single_content(
                record['ACCOUNT_NAME'], 
                record['TEXT']
            )
            if result:
                chunk_results.append(result)
        
        all_results.extend(chunk_results)
        
        # Ara kayÄ±t
        if i % 10 == 0:
            temp_df = pd.DataFrame(all_results)
            temp_df.to_csv(f"{output_file}.temp", index=False)
    
    # Final kayÄ±t
    final_df = pd.DataFrame(all_results)
    final_df.to_csv(output_file, index=False)
    
    print(f"Ä°ÅŸlem tamamlandÄ±: {len(all_results)} kayÄ±t")

# KullanÄ±m
process_large_file("huge_file.csv", "results.csv", "YOUR_API_KEY")
```

### 3. Parallel Processing ile HÄ±zlandÄ±rma

```python
# parallel_processor.py
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import pandas as pd

def process_batch_worker(batch_data):
    """Worker fonksiyonu - ayrÄ± process'te Ã§alÄ±ÅŸÄ±r"""
    from political_analyzer import PoliticalAnalysisSystem
    
    analyzer = PoliticalAnalysisSystem(
        api_key=batch_data['api_key'],
        batch_size=1,
        max_workers=1
    )
    
    results = []
    for item in batch_data['items']:
        result = analyzer.process_single_content(
            item['ACCOUNT_NAME'], 
            item['TEXT']
        )
        if result:
            results.append(result)
    
    return results

def parallel_process_file(input_file, output_file, api_key, num_processes=4):
    """Paralel processing ile dosya iÅŸle"""
    
    # CSV'yi oku
    df = pd.read_csv(input_file)
    data = df.to_dict('records')
    
    # Veriyi process'lere bÃ¶l
    chunk_size = len(data) // num_processes
    chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
    
    # Her chunk iÃ§in worker data hazÄ±rla
    worker_data = [
        {'api_key': api_key, 'items': chunk} 
        for chunk in chunks
    ]
    
    # Parallel processing
    with ProcessPoolExecutor(max_workers=num_processes) as executor:
        results = executor.map(process_batch_worker, worker_data)
    
    # SonuÃ§larÄ± birleÅŸtir
    all_results = []
    for batch_results in results:
        all_results.extend(batch_results)
    
    # Kaydet
    result_df = pd.DataFrame(all_results)
    result_df.to_csv(output_file, index=False)
    
    print(f"Parallel iÅŸlem tamamlandÄ±: {len(all_results)} kayÄ±t")
```

## ğŸ³ Docker ile KullanÄ±m

### Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Sistem baÄŸÄ±mlÄ±lÄ±klarÄ±
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Python baÄŸÄ±mlÄ±lÄ±klarÄ±
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Uygulama dosyalarÄ±
COPY political_analyzer.py .
COPY web_interface.py .

# Veri ve sonuÃ§ dizinleri
RUN mkdir -p /app/data /app/results

EXPOSE 8501

# VarsayÄ±lan komut - web arayÃ¼zÃ¼
CMD ["streamlit", "run", "web_interface.py", "--server.address", "0.0.0.0"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  political-analyzer:
    build: .
    ports:
      - "8501:8501"
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    volumes:
      - ./data:/app/data
      - ./results:/app/results
    restart: unless-stopped

  # CLI versiyonu iÃ§in
  analyzer-cli:
    build: .
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    volumes:
      - ./data:/app/data
      - ./results:/app/results
    command: python political_analyzer.py /app/data/input.csv /app/results/output.csv ${GOOGLE_API_KEY}
    profiles: ["cli"]
```

### Docker kullanÄ±mÄ±:
```bash
# Image build et
docker build -t turkish-political-analyzer .

# Web arayÃ¼zÃ¼ Ã§alÄ±ÅŸtÄ±r
docker run -p 8501:8501 \
  -e GOOGLE_API_KEY=your_key \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/results:/app/results \
  turkish-political-analyzer

# CLI versiyonu
docker run --rm \
  -e GOOGLE_API_KEY=your_key \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/results:/app/results \
  turkish-political-analyzer \
  python political_analyzer.py /app/data/input.csv /app/results/output.csv your_key

# Docker compose ile
echo "GOOGLE_API_KEY=your_key" > .env
docker-compose up  # Web arayÃ¼zÃ¼
docker-compose --profile cli up  # CLI versiyonu
```

## ğŸ”§ Troubleshooting (Sorun Giderme)

### YaygÄ±n Hatalar ve Ã‡Ã¶zÃ¼mleri

#### 1. **ModuleNotFoundError: No module named 'requests'**
```bash
# Ã‡Ã¶zÃ¼m: BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt
```

#### 2. **API Error: 403 Forbidden**
```bash
# Ã‡Ã¶zÃ¼m: API anahtarÄ±nÄ± kontrol edin
# Google Cloud Console'dan yeni anahtar alÄ±n
# Gemini API'nin etkin olduÄŸundan emin olun
```

#### 3. **Rate Limit Error: 429**
```bash
# Ã‡Ã¶zÃ¼m: Rate limit'i artÄ±rÄ±n
python political_analyzer.py input.csv output.csv API_KEY --rate-limit 3.0
```

#### 4. **Memory Error (BÃ¼yÃ¼k dosyalar)**
```python
# Ã‡Ã¶zÃ¼m: Chunk processing kullanÄ±n
# YukarÄ±daki big_file_processor.py kodunu kullanÄ±n
```

#### 5. **CSV Encoding HatasÄ±**
```python
# Ã‡Ã¶zÃ¼m: Encoding belirtin
df = pd.read_csv('input.csv', encoding='utf-8-sig')  # Excel'den gelen dosyalar iÃ§in
df = pd.read_csv('input.csv', encoding='latin-1')   # Eski Windows dosyalarÄ± iÃ§in
```

### Debug Modu

```bash
# DetaylÄ± log iÃ§in
python -u political_analyzer.py input.csv output.csv API_KEY 2>&1 | tee debug.log

# Specific line'da hata varsa
python -c "
import pandas as pd
df = pd.read_csv('input.csv')
print('Problematic rows:')
print(df[df['TEXT'].isnull()])
"
```

## ğŸ“Š Monitoring ve Analytics

### 1. Log Analizi
```python
# log_analyzer.py
import re
from collections import Counter

def analyze_logs(log_file):
    """Log dosyasÄ±nÄ± analiz et"""
    with open(log_file, 'r', encoding='utf-8') as f:
        logs = f.read()
    
    # Error sayÄ±sÄ±
    errors = re.findall(r'ERROR', logs)
    warnings = re.findall(r'WARNING', logs)
    
    # API hatalarÄ±nÄ± analiz et
    api_errors = re.findall(r'API Error: (\d+)', logs)
    error_codes = Counter(api_errors)
    
    print(f"Toplam error: {len(errors)}")
    print(f"Toplam warning: {len(warnings)}")
    print(f"API error kodlarÄ±: {dict(error_codes)}")

# KullanÄ±m
analyze_logs('political_analysis.log')
```

### 2. Progress Tracking
```python
# progress_tracker.py
import json
import time
from datetime import datetime

class ProgressTracker:
    def __init__(self, total_items):
        self.total_items = total_items
        self.processed = 0
        self.errors = 0
        self.start_time = time.time()
    
    def update(self, processed_count, error_count=0):
        self.processed += processed_count
        self.errors += error_count
        
        elapsed = time.time() - self.start_time
        rate = self.processed / elapsed if elapsed > 0 else 0
        remaining = (self.total_items - self.processed) / rate if rate > 0 else 0
        
        print(f"Progress: {self.processed}/{self.total_items} "
              f"({(self.processed/self.total_items)*100:.1f}%) "
              f"Rate: {rate:.2f}/sec "
              f"ETA: {remaining/60:.1f}min")
    
    def save_checkpoint(self, filename):
        checkpoint = {
            'processed': self.processed,
            'errors': self.errors,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(filename, 'w') as f:
            json.dump(checkpoint, f)
```

## ğŸš€ Production Deployment

### 1. Systemd Service (Linux)
```ini
# /etc/systemd/system/political-analyzer.service
[Unit]
Description=Turkish Political Analyzer
After=network.target

[Service]
Type=simple
User=analyzer
WorkingDirectory=/opt/political-analyzer
Environment=GOOGLE_API_KEY=your_key_here
ExecStart=/usr/bin/python3 political_analyzer.py /data/input.csv /data/output.csv
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
# Service'i etkinleÅŸtir
sudo systemctl daemon-reload
sudo systemctl enable political-analyzer
sudo systemctl start political-analyzer
sudo systemctl status political-analyzer
```

### 2. Cron Job ile Otomatik Ã‡alÄ±ÅŸma
```bash
# Crontab'a ekle
crontab -e

# Her gÃ¼n saat 02:00'da Ã§alÄ±ÅŸtÄ±r
0 2 * * * cd /opt/political-analyzer && python3 political_analyzer.py /data/daily_input.csv /data/daily_output_$(date +\%Y\%m\%d).csv $GOOGLE_API_KEY >> /var/log/political-analyzer.log 2>&1
```

### 3. API Server (Flask/FastAPI)
```python
# api_server.py
from flask import Flask, request, jsonify
from political_analyzer import PoliticalAnalysisSystem
import os

app = Flask(__name__)
analyzer = PoliticalAnalysisSystem(os.getenv('GOOGLE_API_KEY'))

@app.route('/analyze', methods=['POST'])
def analyze_content():
    data = request.json
    
    result = analyzer.process_single_content(
        data.get('account_name', ''),
        data.get('text', '')
    )
    
    return jsonify(result)

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## ğŸ“ Destek ve Ä°letiÅŸim

### Dokumentasyon
- **GitHub**: Repository link'i buraya gelecek
- **API Docs**: Google Gemini API dokumentasyonu
- **Issues**: Bug report ve feature request iÃ§in

### Performans SorunlarÄ±
1. **API Rate Limits**: `--rate-limit` parametresini artÄ±rÄ±n
2. **Memory Issues**: Chunk processing kullanÄ±n
3. **Slow Processing**: `--workers` ve `--batch-size` parametrelerini ayarlayÄ±n

### KatkÄ±da Bulunma
```bash
# Development kurulumu
git clone <repository>
cd turkish-political-analyzer
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Test Ã§alÄ±ÅŸtÄ±r
pytest tests/

# Kod formatla
black political_analyzer.py
flake8 political_analyzer.py
```

---

**ğŸ‰ Sistem hazÄ±r! TÃ¼rk siyasi ortamÄ±ndaki sosyal medya analizleri iÃ§in kapsamlÄ± bir Python Ã§Ã¶zÃ¼mÃ¼.**